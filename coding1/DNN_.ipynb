{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------best scenario-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leo/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:90: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/5] train_loss: 5.930  train_accuracy: 63.211%  validation_loss: 4.785  validation_accuracy: 70.314%\n",
      "[Epoch 2/5] train_loss: 4.848  train_accuracy: 69.922%  validation_loss: 4.256  validation_accuracy: 73.592%\n",
      "[Epoch 3/5] train_loss: 4.141  train_accuracy: 74.309%  validation_loss: 4.031  validation_accuracy: 74.988%\n",
      "[Epoch 4/5] train_loss: 3.757  train_accuracy: 76.693%  validation_loss: 4.027  validation_accuracy: 75.017%\n",
      "[Epoch 5/5] train_loss: 3.461  train_accuracy: 78.526%  validation_loss: 4.064  validation_accuracy: 74.784%\n",
      "Best accuracy => train_accuracy: 78.526%  validation_accuracy: 75.017%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEXCAYAAABlI9noAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd3wUdf748dc7DZLQA0QghNCrCFIEREURFPWsWEAUsGA/9c56d7bv2c7zd6ee7WxgAQSsZ8cCVjqhFylCCCUEJJRAQsr798dMZIkpG9jd2Wzez8cjj+xOfe/M7rxnPp/PfEZUFWOMMSYQorwOwBhjTOSwpGKMMSZgLKkYY4wJGEsqxhhjAsaSijHGmICxpGKMMSZgLKkYY4wJmIAmFRHZICKnB3KZ1ZWITBCRhysYv09E2pQzboyI/FDBvDNF5JpAxBloIpLqfrZor2MxNZeIPCgib4VgPWkioiISE6DlVfvfT9heqYjI7SKyTUR2i8hrIlKrgmkHi8gqEdkvIjNEpJXPuFru/Hvc5f2pCvNOEJGD7k7eF8idrap1VHV9IJYVTlQ1w/1sRRCcBCgip7r7areIbCg1rqmITBaRLe74H0XkhFLT3CIiv7jfifkiMjCQ8YUbERkkIplexwEgIj1EZIH7e1sgIj0qmDZNRD4VkV3ub/fZQB28K4mxwpO6YCr9+wk2EYkWkYfd38teEUkXkQZlTPeNv8kzZEmlKl8GETkDuAcYDKQBbYCHypm2MfAecB/QCJgPTPGZ5EGgPdAKOBW4S0TO9HNegCfcnVwnlDvbVCgXeA24s4xxdYB5QC+cffo68ImI1AFwE8zjwHCgPvAq8H51PjOsLkQkDvgQeAtoiLNvPnSHl+V5YDvQDOgBnALcGIJQa5KHgAFAf6AecAWQ5zuBiFwO+J/MVTVgf8AG4HT39YPAOzhfoD3ANVVYziTgUZ/3g4Ft5Uw7DvjJ530icADo5L7fDAz1Gf934G0/550APHyE22IC8BzwCbAXmAO09RmvQDv3dRLwP3c7zXVj/MFn2iHAKmA38Czwre/2BK4CVgK7gC+AVqXWcz2wxh3/HCCVxP4g8JbP+zR3OTHu+5lujD+6n2060Lj0tMAjQBHOl3SfG7sA/8Y5WOwGlgDdjnAbnw5s8GO6PUAv9/WlwNxS+1yBZn6uU3EObGvcz/53oC0wy13PVCDOZ/prgbXAr+4+bn4UyzoHWATkAD8B3Uv99u5wt+dunJOj2hz6The7+2Af0JxS321gEJBZanl3usvLxUm+ycBnbqxfAQ2ruL+G4vwexWdYBnBmOdOvBM7yef9P4L9+rutBnOPPFDfehcBxPuPvAda541YAF7jDO7vf1yJ3W+W4w+OB/wdsdLfvD+6wNHc/jnY/yw7gr37E1xfnJHYPkAX8q4zfT3+ffbbPjWuDO12Uz2fY6X5XGlVxfzR0l9u2gmnqAz8D/fA5BlS43CP5MVcQwAYOTyoFwPnuBogHRuL8IMr7S3XnXQxc6rPcxu4HSipjnU8DL5Qatgy4yN1oCiT7jBsOLK1sXvf1BJyDwa/AgpLhfm6Lknn7ul+QibjJzOeAUpJU3na/FIlAN5wf3g8+n32PG3cscDtQiJtU3O27FufHEAP8jcMTpQIfAw2AVCCbcn7EpX6QlSWVdUAHd7/OBB6vYFrfBHiGuy0b4CSYzrgHdJwfSbnfjzLirDSp4Jzh5gH13ff13PWfAEQDtwDpVJJoS23P/7nL6QrkA1/jXE3XxzlAjXanPQ3nIHM8UAv4D/DdES7reJxEXBL3aJzfWy2f395cnITRCOeAfL07bhA+CcPn+1lZUpmNk0hauOteCPR0P8s3wAM+01f0u77HneZ24LNScXwM/LmcbX098AaQ4MawDPfg78d+ehDn+FPyu7kD+AWIdcdf7G6rKJwTjVwOfQ/H4HNS5w57Due73MLd/gPc7ZDm7seXcX4Lx7n7sXMl8c0CrnBf1wH6lfX78Zk+1l3/Y+7729z9k+LG8V9gchX3x8nu+7uBbTjJ46YyPvft5cVV5mfz9yDp547cwOFJ5bsjXM46fA587gZVIK2MaV/FPaD5DPvR/WK0dOer7TNuCIeyfbnz+vyQk3AO1mfhnNWc6OdnmAC84vP+LGBVqQNKO/cLWoB7deSOe5RDSeVKYLbPOAEyOZRUPgOu9hkfBezHvVpx1zPQZ/zUki9VJT/IypLK33zG3wh8XsG0vknlNA6d+UQd5fetwqSCc7BeCtxbavv9xd3mhTgH/T5VWKf6fgdwEtTdPu//H/CUz/frCZ9xddz1ph3Bsl4A/l4qltXAKT6/vVE+454AXnRfD+LIksrlPu/fxecEDCcZf1DF/XUfPidW7rCJwIPlTN/Z3SaF7raagP/J/0EO/91EAVuBk8qZfhFwnvt6DIeXFEThXO0dV8Z8Jd/3FJ9hc4HLKonvO5yip8blLK90UnkBp9Qjyn2/EhjsM76Z+92q9KDvM89Id12v4iTE7jgnnUPc8b3d7RJTXlxl/QW7TmXTEc63D+eAUKLk9V4/pi2Zfq87Dn6/rJLlVDQvqrpQVXeqaqGqforzA7iwCp9jm8/r/TgHldKa4Ow032210ed1c99x6uxt32lbAU+LSI6I5OBcHQnOGVVV4qiqI1qmqn6DUwz2HJAlIi+JSOl9cNREJB74COfA8pjPqGtwigu7AnHAKOBjEWlehcVn+bw+UMb7km3RHJ99qar7cIoqfPeNv8tqBfy5ZD+7+7qlu44Sgd7P/sbmrwp/b75EJAqnKPc9nCv4xjglD/+owvp8fzfFOCdjzd3lXykii3y2ZTd3HWVpjFOUuK6CdVV121+Nc6W/SkTmicg55U0oItfhJP2R7ucA5/vwvk/8K3GK7JIrWa+vA+7//1PVA6q6BKfU5Cx3+z8P3KqqhVVYZtCTivq+EZHLS7WkKv2X6k66HOcyssRxQJaq7ixjHYdNKyKJOOXSy1V1F87ZSellLa9s3go+j1T8kassG+dMrKXPsFSf11t9x4mIlJp2E3Cdqjbw+YtX1Z+OIqZcnCKHEsccxbL0dwNUn1HVXjgH9g64Fe4i8peKvh/+rtBtKfgBTjHidaVGHwd8pKo/q2qxqn6Os40HHNnHq9AWnB9/SVyJOFe+m49gWZuAR0rt5wRVnezHvL/bBwR2H1PJ7/ov7mTLge7ud7hEd8r+vTXC+Z4/q6r57m9/PM4Vv798fzdROEVFW9wWni8DN+MUqTfAKVoriav09tqBU4TatgrrrpCqrlHVEUBTnET5jvv9OIyInIRT13aequ72GbUJGFbq+1BbVTe78/mzP5aU83nBSfa9gSkisg2n8QtAphtTuULapFhVJ+rhLalK/2W4k74BXC0iXUSkIU49wYRyFvs+0E1ELhKR2sD9wBJVXeWzrL+JSEMR6YRTcTrBn3lFZLiI1BGRKBEZinNW+7+SFbtN7AYd5TYpwjkbe1BEEkSkC055eYlPgK4icqHbgu6PHH4AeBG4V0S6ujHVF5GLjyYmnEvek8VpM18fuPcolpWFU0eAG18fETlBRGJxDmwllaKo6qMVfT98lhHl7q9Y563ULmlB5C73HZyzsCt9zuxKzAPOFpE24hiCk9iWufOPkVLNlI/CJGCsOM1oa+EUa85R1SNZ/svA9e62ExFJFJGzRaSuH/NmAUnuviyxCOeMtJGIHINTRn/EKvldP+pONhNnX/9RnKb+N7vDvyljeTtw6kBuEJEYcZq5jsapbwV+uy9uTAVh9fL53dyGU9cxm0ONM7Ld5YzFuVIpkQWklHyn3O/Qa8C/RKS5OM1w+0sFtzlURkRGiUgTd9k57uCiUtO0xGlocKWq/lxqES8Cj7gJEhFpIiLnlYz0Z3+o6jrge+Cv7v7ojFO/9DFOY4TmOHWSPTiUzHvhNDoqV1jep+KePT4BzMApPtgIPFAyXkSWi9PMDVXNxqmUfwSnddMJwGU+i3sA57J1I06rqX+6y/dn3ltxzipzcFqeXKuqM90YUnAu55cG4CPfjHO5vA0n4Y0vGeH+uC7GaQa7E6d59I8+49/HOdN5W0T24Bwchx1NMKr6Jc6XeQlOmfbHR7G4p4Hh4txr8AzOGdDLONt7I85nerKKyzwZJ2l8inNVdwCnBRo4Vxzn4LQ0yvE5Oys5u3oD5xJ/Jk4DiGdwrvRKTkJa4rN9j4aqfo1Tj/AuztVQWw7/flVlWfNxToiexdl2a3HK/v2ZdxUwGVgvTnFJc+BNnAP0BpxtV7opfcCp6kGchiVX4vymrgLOd4eXXKl+5jPLhcCZOAf/tThX9Le708bhXPXNrmCVH+IcJHfhNJW9UFULVHUFTn3VLJwEciyH7/NvcK6etonIDnfYHTi/9Xk4Rcz/4OiOn2cCy90r8Kdx6mDySk0zGOcE8h2f73HJVd3TOCe400VkL852OIGqG4FzNb0T5wT2PlX9Wh3bSv5wEzBOidHBihYoboWMqSIRGQV0VdWjOYs3YUZEpuOUI6/0OhZTPnFuWL3JLUIyYcSSijHGmIAJy+IvE3wi8mI5lXgveh2bMZFARD6rpKI8ItmVijHGmIAJeudsgdC4cWNNS0vzOgxjjKlWFixYsENVm4RyndUiqaSlpTF//nyvwzDGmGpFRDZWPlVgWZ2KMcaYgLGkYowxJmAsqRhjjAmYalGnUpaCggIyMzPJyyt9E6rxVbt2bVJSUoiNjfU6FGNMDVBtk0pmZiZ169YlLS0NkUD38RgZVJWdO3eSmZlJ69atvQ7HGFMDVNvir7y8PJKSkiyhVEBESEpKsqs5Y0zIVNukAlhC8YNtI2NMKFXrpGKMMZEqY+d+Xvl+PTn7K+wUOOxYUjlCOTk5PP/881We76yzziInJ6fCae6//36++uqrIw3NGFMNqSpLM3fzr+mrOfOp7zj5nzN4+JOVzF7/q9ehVUm16Purd+/eWvqO+pUrV9K5c2ePIoINGzZwzjnnsGzZssOGFxUVER0d7VFUZfN6WxljylZQVMyc9b8yfcU2vlqRxZbdeUQJ9E5rxNAuyQztcgypSQmVL6gcIrJAVXsHMORKVdvWX1675557WLduHT169CA2NpY6derQrFkzFi1axIoVKzj//PPZtGkTeXl53HrrrYwbNw441OXMvn37GDZsGAMHDuSnn36iRYsWfPjhh8THxzNmzBjOOecchg8fTlpaGqNHj+ajjz6ioKCAadOm0alTJ7Kzsxk5ciQ7d+6kT58+fP755yxYsIDGjct7zLYxJhzsyy/k29XZTF+xjRmrtrMnr5DasVGc1L4Jtw/pwODOyTRKjPM6zCMWEUnloY+Ws2LLnoAus0vzejzwh67ljn/88cdZtmwZixYtYubMmZx99tksW7bst6a7r732Go0aNeLAgQP06dOHiy66iKSkpMOWsWbNGiZPnszLL7/MJZdcwrvvvsuoUaN+t67GjRuzcOFCnn/+eZ588kleeeUVHnroIU477TTuvfdePv/8c1566aWAfn5jTOBs35PHVyu3M33FNn5au5ODRcU0TIjljK7HMKRLMie1b0J8XHiVcBypoCUVEenI4Y8obYPzDPiZOM9Xro3zeNAbVXVusOIIlb59+x52L8gzzzzD+++/D8CmTZtYs2bN75JK69at6dGjBwC9evViw4YNZS77wgsv/G2a9957D4Affvjht+WfeeaZNGzYMKCfxxhzdNZu38f0Fdv4ckUW6RlOPWpqowSu7N+KIV2S6dWqITHRkVetHbSkoqqrgR4AIhKN86z393GeT/6Qqn4mImfhPIt+0NGsq6IrilBJTEz87fXMmTP56quvmDVrFgkJCQwaNKjMe0Vq1ar12+vo6GgOHDhQ5rJLpouOjqawsBBwKvWMMeGjuFhJ35TzWyJZn50LwLEt6vPnIR0Y2vUYOiTXifhm/qEq/hoMrFPVjSKiQD13eH1gS4hiCKi6deuyd+/eMsft3r2bhg0bkpCQwKpVq5g9e3bA1z9w4ECmTp3K3XffzfTp09m1a1fA12GMqVheQRGz1u10E8l2duzLJyZK6N82iTED0ji9czLNG8R7HWZIhSqpXAZMdl/fBnwhIk/iNGkeUNYMIjIOGAeQmpoaihirJCkpiRNPPJFu3boRHx9PcnLyb+POPPNMXnzxRbp3707Hjh3p169fwNf/wAMPMGLECKZMmcIpp5xCs2bNqFu3bsDXY4w53O79BXyzOosvV2Qxc3U2+w8WkRgXzaBOTRnaJZlBHZtSP77m9rUX9CbFIhKHczXSVVWzROQZ4FtVfVdELgHGqerpFS0jHJsUey0/P5/o6GhiYmKYNWsWN9xwA4sWLSpz2pq+rYw5WptzDvDl8m18uTKLOet/pbBYaVK3FkO6JDO0SzL92yZRKyb8KtojtUnxMGChqma570cDt7qvpwGvhCCGiJORkcEll1xCcXExcXFxvPzyy16HZEzEUFVWbdvL9OVZTF+xjeVu69J2Tetw7cltGNolmeNSGhAVFdn1I0ciFEllBIeKvsC5ajkFpxXYacCaEMQQcdq3b096errXYRgTMQqLipm3YRdfrnASSeauA4jA8akNuXdYJ4Z0SaZNkzpehxn2gppURCQBGAJc5zP4WuBpEYkB8nDrTYwxJtT2Hyzku5938OWKLL5elUXO/gLiYqIY2K4xN5/ajsGdk2lSt1blCzK/CWpSUdX9QFKpYT8AvYK5XmOMKc/Offl87d6I+P2aHeQXFlM/PpbT3Ir2kzs0IbFWRNwX7gnbcsaYiLdhR+5vxVoLNu6iWKFFg3hG9E1laJdk+rRuRGwE3ojoBUsqxpiIU1ysLN28+7dE8nPWPgA6N6vHLae1Z0iXZLo2rxfxNyJ6wZLKEcrJyWHSpEnceOONVZ73qaeeYty4cSQkOL2PnnXWWUyaNIkGDRoEOkxjaoyDhcXMXr/T7fF3O9v25BEdJfRNa8T956QypEsyLRsdeY+/xj+WVI5QyfNUjjSpjBo16rek8umnnwY6PGNqhL15Bcxcnc30FVnMXLWdvfmFxMdGc0qHJgzpksxpnZrSsBr3+FsdWVI5Qr5d3w8ZMoSmTZsydepU8vPzueCCC3jooYfIzc3lkksuITMzk6KiIu677z6ysrLYsmULp556Ko0bN2bGjBl+dYc/b948rr76ahITExk4cCCfffbZ757lYkxNkLUnzy3WymLWuh0UFClJiXGcdWwzhnRJZmD7xtSODb8bEWuKyEgqn90D25YGdpnHHAvDHi93tG/X99OnT+edd95h7ty5qCrnnnsu3333HdnZ2TRv3pxPPvkEcPoEq1+/Pv/617+YMWNGmc8+Ka87/LFjx/LSSy8xYMAA7rnnnsB+VmPCmKq6Pf46iWTxJqfH37SkBMae2JqhXZLpmdqQaLsRMSxERlLx2PTp05k+fTo9e/YEYN++faxZs4aTTjqJO+64g7vvvptzzjmHk046qdJlldUdfk5ODnv37mXAAKebtJEjR/Lxxx8H7wMZ47GiYiU9YxfTVzh9bP2yw+nx97iWDbjzjI4M7ZJMu6aR3+NvdRQZSaWCK4pQUFXuvfderrvuut+NW7BgAZ9++in33nsvQ4cO5f77769wWWV1h2/d3JuaIK+giB/WODcifrUyi525B4mNFvq3bcxVA1szpHMyx9Sv7XWYphKRkVQ84Nv1/RlnnMF9993H5ZdfTp06ddi8eTOxsbEUFhbSqFEjRo0aRZ06dZgwYcJh8/r76N+GDRtSt25dZs+eTb9+/Xj77beD9bGMCalduQf5ZtV2vlyRxbc/Z3OgoIi6tWJ+6/H3lI5NqFe75vb4Wx1ZUjlCvl3fDxs2jJEjR9K/f38A6tSpw1tvvcXatWu58847iYqKIjY2lhdeeAGAcePGMWzYMJo1a8aMGTP8Wt+rr77KtddeS2JiIoMGDaJ+/fpB+2zGBNOmX/f/dv/IvA27KCpWkuvV4qJeLRja5Rj6tUkiLsZuRKyugt71fSBY1/dOPU2dOk5ndo8//jhbt27l6aef9mvemratTPjJ2X+Qdxdu5t0FmazY6vT42yG5DkO7OM9oP7ZFfevxNwgitet7EwCffPIJjz32GIWFhbRq1eq3ojRjwpWqsjAjh4lzNvLJkq3kFxZzXMsG/PWszgzpkkxa48TKF2KqHUsq1cSll17KpZde6nUYxlRqT14BH6ZvZuKcDFZt20tiXDTDe6Uw8oRUuja3YttIV62Tiqpak8JKVIfiTRMZlmTmMGlOBh8u2sKBgiK6tajHoxccy7k9mlPHev2tMartnq5duzY7d+4kKSnJEks5VJWdO3dSu7Y1wzTBkZtfyP8Wb2HSnAyWbt5NfGw05x7XnMv7pdI9xfqyq4mqbVJJSUkhMzOT7Oxsr0MJa7Vr1yYlJcXrMEyEWbl1DxPnbOSD9C3syy+kY3Jd/u+8rpzfs4U1Aa7hqm1SiY2NpXXr1l6HYUyNkVdQxMdLtjJpzkYWZuQQFxPFOcc24/J+qRyf2tBKDAwQxKQiIh2BKT6D2gD3q+pTInILcDNQCHyiqncFKw5jzNFZu30vE+dk8O6CTPbkFdKmSSJ/O7szw3ul0CDBegA2hwtaUlHV1UAPABGJBjYD74vIqcB5QHdVzReRpsGKwRhzZPILi/h82TYmzslg7i+/EhstnNmtGSP7ptKvTSO7KjHlClXx12BgnapuFJF/Ao+raj6Aqm4PUQzGmEps2JHL5LkZTFuQya+5B0ltlMA9wzoxvFcKjevUqnwBpsYLVVK5DJjsvu4AnCQijwB5wB2qOq/0DCIyDhgHkJqaGqIwjal5CoqK+XJFFpPmZPDD2h1ERwlDOidzeb9UTmzb2O50N1US9KQiInHAucC9PutsCPQD+gBTRaSNlrqhQlVfAl4Cp5uWYMdpTE2z6df9vD0vg6nzM8nem0+LBvH8eUgHLunTkuR61gzdHJlQXKkMAxaqapb7PhN4z00ic0WkGGgMWNtgY4KssKiYGauzmThnI9/+nI0Ap3VqysgTUjmlQ1N70JU5aqFIKiM4VPQF8AFwGjBTRDoAccCOEMRhTI21bXceb8/LYMq8TWzdnUfTurW45dR2XNo3lRYN4r0Oz0SQoCYVEUkAhgC+T696DXhNRJYBB4HRpYu+jDFHr7hY+W5NNhPnZPDNqu0UFSsnd2jCA3/oyuDOTYmNtu7lTeAFNamo6n4gqdSwg8CoYK7XmJose28+U+dvYvLcDDJ3HSApMY5xJ7dhRJ9UUpMSvA7PRLhqe0e9MeaQ4mJl1vqdTJqTwRfLt1FYrPRvk8Q9wzoxtMsx9tArEzKWVIypxn7NPcg7CzYxee4mftmRS4OEWMYMSGPECam0bVLH6/BMDWRJxZhqRlWZt2EXE+ds5LOl2zhYVEyftIb8cXA7hnVrRu3YaK9DNDWYJRVjqond+wt4Lz2TSXMyWLN9H3VrxzCib0tGntCKjsfU9To8YwBLKsaENVUlfZPz8KuPl2whr8B5JO8TF3XnnOOakRBnP2ETXuwbaUwY2ptXwAeLnIdfrdy6h8S4aC48PoWRfVPp1iIIj+RVdf7w/V98+DAtLmc8lYz3mV8EYuIh1v2LsqK6SGNJxZiq2rMFMmbBxlmwfSVokZ8HYCoZr+QXFrEvr4D9+QUMUmVojFCnQTTxsULUemB9ZQd4ddbzu/GVzOOV6FoQlwCxCYcSzW+vE0q9jv/9dHFlTeM7bwJE22EulGxrG1MRVdixBjJ+gozZsPEnyNnojItNhGO6QXQcSJRzFo44/yXq0GukjPGHXhcWw5bd+WzYuZ9dBwqJEqF5w0RaN6lDw8Q4hCh3fqqwfN/xHFV8lS/fdzwVj1eFwjwo2A8FB8r4fwAO5sLB/ZC78/fji/Krvg+jYstJRhUkq9gKEl1ZSTA67tDnr+EsqRjjq6gAti5xrkRK/vbvdMYlNIZW/eGE6yC1PxzT/ajOgldt28OkORm8v3Aze/ML6ZBch5GnpHLB8SnUj7dH8papqBAKD5SdkA7uLztJFez3+Ss1b95Wdz6fYYUHqh6XRB3BlZWfV2WJTSC2+nTwaUnF1GwHcyFznlOUlTHLeV2w3xnXMA3an+EkktT+kNTuqM9G8wqK+HTpVibOyWDBxl3ExURx9rHNGHlCKr1b2SN5KxUdA9F1oVYQW7sVF7tXUwegILf8K6qC/aUSWenp3Nf7d5R9NeZvsePIadBhaPA+b4BZUjE1S+4OpxgrY5ZTlLV1sVMngjhFWT2vgNR+ThKp1yxgq127fR+T52bwzoJMdh8ooE1j55G8Fx2fQsNEeyRvWImKcq4o4hIo1ctU4KhCYX45CSn38GHJXYMTQ5BYUjGRS9Wp/9g461CdyI6fnXHRtaBFLxh4G6QOgJZ9oHZgW1XlFxbxxfIsJs3ZyOz1ziN5h3Y9hstPSKV/myS7KqnJRJwirWpUrOUvSyomchQXwfYVhyrUM2bB3q3OuNr1oWU/6DHSuQpp3hNigvN43I07c5k0N4N35meyM/cgLRvFc9eZHbm4V0ua1LVH8prIZknFVF+F+bB54aGrkIw5kL/bGVe3ObQa4CSQVgOgSWenWCNICoqK+XplFhPnZPD9GueRvKd3bsrIE1pxUjt7JK+pOSypmOrjQA5smnuoVdbmhYeamDbuCN0ucIqyUvtBg9SQNPHcnHOAt+c6D7/avjefZvVrc/vpHbi0T0uOqR95RRvGVMaSiglfe7Y6VyEbZzlXIlnLAIWoGGjWA/pe61yFtOwHiUGqUC1HQVExT36xmpe/X48Cp3Zsysi+qQzq2IQYe/iVqcGCllREpCMwxWdQG+B+VX3KHX8H8E+giara44RruspuMmzZBwbd6zTvbdEL4hI9CzVz135umZxOekYOI/q25KZT25HS0B5+ZQwEMamo6mqgB4CIRAObgffd9y1xHjOcEaz1mzBXVADblhy6PySINxkG0hfLt3HntMWowrMje3JO9+Zeh2RMWAnVL3UwsE5V3VNP/g3cBXwYovUbr5XcZFhyFZI532mPD9Cwtc9NhgMgqW3YdXmRX1jE45+tYvyPGzi2RX2eHdmTVkneXS0ZE65ClVQuAyYDiMi5wGZVXWzt9COY702GGbOcmwyLCzl0k+GooNxkGAwbd+Zy86R0luEH6FkAACAASURBVG7ezdgT07hnWCdqxVjvusaUJehJRUTigHOBe0UkAfgrUGmfAyIyDhgHkJqaGtQYzVE67CZD96/0TYYn3hq0mwyD6ZMlW7nn3SWIwH+v6MUZXY/xOiRjwloorlSGAQtVNUtEjgVaAyVXKSnAQhHpq6rbfGdS1ZeAlwB69+7tYd/c5nd+d5PhbNi7xRkXwpsMgymvoIiHP1nBW7Mz6JnagP+M6GmV8cb4IRRJZQRu0ZeqLgWalowQkQ1Ab2v9FeYqvcmwf8huMgyF9dn7uGlSOiu37uG6k9twxxkdibVmwsb4JahJxS3uGgJcF8z1mADL2+3cZFjS1UkY3GQYKh+kb+Yv7y+lVkwUr43pzWmdkr0OyZhqJahJRVX3U0E3n6qaFsz1myooKoD542HhG2F1k2GoHDhYxIP/W86U+Zvok9aQZ0b0pFn9eK/DMqbaCY/G/8Y7qrD6U/jyfti5FlLC5ybDUFmTtZebJi1kzfZ93HxqO247vb3dFW/MEbKkUpNtXgjT74ONPzjFWiOnQvuhEVWcVRFVZdqCTO7/cBl1asXwxlV9Oal9E6/DMqZas6RSE+VkwNd/h6VTnbvXz/4XHD86bO5aD4Xc/ELu+2AZ76Vvpn+bJJ6+rAdN61kHkMYcrZpzFDFOBfwP/4ZZzztXIyf9GU68DWrX8zqykFq5dQ83TVrIhh253H56B24+rR3R1jW9MQFhSaUmKCqABRNg5mNO/1rdL4PB90H9FK8jCylVZdLcDB76aAUN4mOZeE0/+reNzIYHxnjFkkokU4XVn7mV8Gsg7SQY+jA07+F1ZCG3N6+Ae99bysdLtnJS+8b8+9IeNK5T/W7KNCbcWVKJVFvSnUr4Dd9DUnsY8TZ0OLPGVML7WrZ5NzdNWkjmrgPcdWZHrj+5rT2J0ZggsaQSaXI2wTd/hyVT3Er4/+dWwsd6HVnIqSqv/7SBRz9dRVKdON4e148+aY28DsuYiGZJJVLk7XEq4Wc/77wf+CcYeFu16rwxkHbvL+CudxfzxfIsBndqypMXH0fDxDivwzIm4llSqe6KCmHhBJjxGOzfAd0vhdPugwYtvY7MM+kZu7hlcjrbdufxt7M7c/XA1thjFowJDUsq1ZUq/Py5Uwm/42doNRDOeNjpFbiGUlVe+f4X/vH5KpLr1Wba9f3pmdrQ67CMqVEsqVRHWxbB9L8dqoS/bDJ0HFYjK+FL7Mo9yB3TFvP1qu2c0TWZJy46jvoJNa8eyRivWVKpTnZnOnfCL3kbEpLgrCeh15gaWQnva/6GX7llcjo79x3koXO7cmX/VlbcZYxHLKlUB3l74MenYNZzTrHXibfBSX+qsZXwJYqLlRe+Xce/vvyZlIbxvHvDAI5NqdnbxBivWVIJZ0WFsPB150743Gw49hLnTvgG9njlHfvyuX3KIr5fs4NzujfjsQuPpW7tmn3FZkw48CupiMi7wGvAZ6paHNyQjFMJ/4VbCb8aWp3o9CDc4nivIwsLs9bt5Na308k5UMCjFxzLiL4trbjLmDDh75XKC8BY4BkRmQZMUNVVwQurBtu62KmE/+U7SGoHl02CjmfV6Er4EkXFyn++WcMzX68hrXEir1/Vl87NalZnmMaEO7+Siqp+BXwlIvVxnjn/pYhsAl4G3lLVgtLziEhHYIrPoDbA/UAL4A/AQWAdMFZVc47qU0SC3Zvhm4dh8WSIbwjD/gm9x9b4SvgS2/fkcduURfy0bicX9mzB38/vRmItK701Jtz4/asUkSRgFHAFkA5MBAYCo4FBpadX1dVAD3feaGAz8D7QEbhXVQtF5B/AvcDdR/UpqrP8vfBDSSV8MZz4R6dL+hpeCe/r+zXZ3D5lEfvyC3lieHcu7pVixV3GhCl/61TeAzoBbwJ/UNWt7qgpIjLfj0UMBtap6kZgo8/w2cDwKsQbOYoKIf0NmPGoUwnfbTgMvh8atvI6srBRWFTMU1+t4bmZa2nftA6Tr+1H++S6XodljKmAv1cqz6rqN2WNUNXefsx/GTC5jOFXcXgRWeRThTVfwpf3QfYqSB0AI6ZASi+vIwsrW3cf4NbJi5i74Vcu7d2SB8/tSnxctNdhGWMq4W9S6SwiC0vqPkSkITBCVZ+vbEYRiQPOxSnm8h3+V6AQpxitrPnGAeMAUlMjpAnt1iVuJfy30KgtXDoROp1tlfClzFi1nT9NXUR+YTFPXdqD83u28DokY4yfRFUrn0hkkar2KDUsXVUr7WhKRM4DblLVoT7DRgPXA4NVdX9ly+jdu7fOn+9PKVuY2rPFqYRfNMmphB90D/QaCzHWa66vgqJinvxiNf/9bj2dm9XjuZE9adOkjtdhGVNticgCP0uTAsbfK5UoERF1M5Bb8e7vEXEEPkVfInImTsX8Kf4klGotfy/8+DT89CxoEQy4xamEj2/gdWRhJ3PXfm6ZnE56Rg6j+qXyt7O7UDvWiruMqW78TSpfAFNF5EVAca4yPq9sJhFJAIYA1/kMfhaohdMsGWC2ql5flaDDXlEhpL/pVsJvh24XweAHrBK+HF8s38ad0xajCs+O7Mk53Zt7HZIx5gj5m1TuxkkMNwACTAdeqWwm90okqdSwdlWMsfpQhbVfOY/xzV4JLfvBiMmQEtKrz2ojv7CIxz9bxfgfN3Bsi/o8O7InrZISvQ7LGHMU/L35sRjnrvoXghtONbZtqVMJv34mNGoDl7wJnf9glfDl2Lgzl5snpbN0827GnpjGPcM6USvGiruMqe78vU+lPfAY0AWoXTJcVdsEKa7qY88W+OYRWDTRqSs58x/Q+yqrhK/AJ0u2cs+7SxCB/17RizO6HuN1SMaYAPG3+Gs88ADwb+BUnH7AavYpeP4++OkZ+Ok/UFwIA252K+HtSYPlySso4uFPVvDW7Ax6pjbgPyN6ktIwweuwjDEB5G9SiVfVr90WYBuBB0Xke5xEU7MUFzmV8N884lTCd73QuRO+UWuvIwtr67P3cdOkdFZu3cN1J7fhjjM6Ehsd5XVYxpgA8zep5IlIFLBGRG7G6cerafDCClNrvnLuhN++Alqe4PQg3LKP11GFvQ/SN/OX95dSKyaK18b05rROyV6HZIwJEn+Tym1AAvBH4O84RWCjgxVU2Nm2zEkm676Bhq3hkjeg87lWCV+JAweLePB/y5kyfxN90hryzIieNKsf73VYxpggqjSpuDc6XqKqdwL7cOpTaoY9W2HGw5A+0ek1+IzHoM81VgnvhzVZe7lp0kLWbN/Hzae247bT2xNjxV3GRLxKk4qqFolIL9876iNe/j6nAv6nZ6CoAPrfBCffYZXwflBVpi3I5P4Pl1GnVgxvXNWXk9o38TosY0yI+Fv8lQ586D71MbdkoKq+F5SovFJc5DQN/uYR2LcNul7g3AlvlfB+yc0v5L4PlvFe+mb6t0ni6ct60LRe7cpnNMZEDH+TSiNgJ3CazzAFIieplNwJv30FpPSFS9+Eln29jqraWLl1DzdNWsiGHbncfnoHbj6tHdFRVudkTE3j7x31kVuPkrXcSSbrvoaGaXDxBOhyvlXC+0lVmTQ3g4c+WkGD+FgmXtOP/m2TKp/RGBOR/L2jfjzOlclhVPWqgEcUKnu2wgz3Tvha9eCMR91K+FpeR1Zt7M0r4N73lvLxkq2c1L4x/760B43r2PYzpibzt/jrY5/XtYELgC2BDycEDuY6lfA/Pu1Uwp9wg1MJn9DI68iqlWWbd3PTpIVk7jrAXWd25PqT2xJlxV3G1Hj+Fn+96/teRCYDXwUlomApLnIekvXNw04lfJfz4PQHnc4fjd9Uldd/2sCjn64iqU4cb4/rR580S8jGGIe/VyqltQeqzzN+137tVsIvh5Q+zs2LqSd4HVW1s3t/AXe9u5gvlmcxuFNTnrz4OBom2j07xphD/K1T2cvhdSrbcJ6xEt6yVjh3wq/9Chq0guHjnWbCVglfZekZu7hlcjrbdufxt7M7c/XA1ohtR2NMKf4Wf9UNdiBBMfe/kDkPhj4MfcdZJfwRUFVe+f4X/vH5KpLr1Wba9f3pmWo3gRpjyubvlcoFwDequtt93wAYpKofVDBPR2CKz6A2wP3AG+7wNGADThcwu44k+EoNfsD5s0r4I7Ir9yB3TFvM16u2c0bXZJ646DjqJ8R6HZYxJoz52xnTAyUJBUBVc6ik23tVXa2qPVS1B9AL2A+8D9wDfK2q7YGv3ffBkdDIEsoRmr/hV8565nu+X7ODh87tyoujellCMcZUyt+K+rKST1Uq+QcD61R1o4icBwxyh78OzKQ61M/UEMXFygvfruNfX/5MSsN43r1hAMem1Pc6LGNMNeFvYpgvIv8CnsOpsL8FWFCF9VwGTHZfJ6vqVgBV3SoiZT6XRUTGAeMAUlOrT0Oz6uzX3IPcNmUR3/2czTndm/HYhcdSt7ZdnRhj/Odv8dctwEGcupCpwAHgJn9mFJE44FxgWlUCU9WXVLW3qvZu0sR6uQ223PxCRr82l9nrd/LIBd34z4iellCMMVXmb+uvXI687mMYsFBVs9z3WSLSzL1KaQZsP8LlmgApLCrm5kkLWb5lNy9f2ZvBne3JjMaYI+PXlYqIfOm2+Cp531BEvvBzHSM4VPQF8D8OPTVyNPChn8sxQaCq3Pfhcmaszubv53ezhGKMOSr+Fn81dlt8AeA2Aa70GfUikgAM4fAu8h8HhojIGnfc4/6HawLt+ZnrmDw3gxsHteXyE1p5HY4xpprzt6K+WERSVTUDQETSKKPX4tJUdT+QVGrYTpzWYMZj76dn8s8vVnNej+bcMbSj1+EYYyKAv0nlr8APIvKt+/5k3JZZpnr6ae0O7npnCf3aNOKJ4d2th2FjTED4W1H/uYj0xkkki3DqQQ4EMzATPKu37eW6NxfQunEi/72iN7Vior0OyRgTIfztpuUa4FYgBSep9ANmcfjjhU01sG13HmPGzyWhVjTjx/alfrw1GzbGBI6/FfW3An2Ajap6KtATyA5aVCYo9uYVMGb8XPYcKOC1MX1o0SDe65CMMRHG36SSp6p5ACJSS1VXAVazW40UFBVz48SFrN2+jxdG9aJrc+t6xRgTeP5W1Ge696l8AHwpIruoro8TroFUlXveXcr3a3bwz+HdObmD9VBgjAkOfyvqL3BfPigiM4D6wOdBi8oE1L+/WsO7CzO57fT2XNy7pdfhGGMiWJUfJ6yq31Y+lQkXU+Zl8MzXa7i4Vwq3Dm7vdTjGmAjnb52KqYZmrt7OX95fxkntG/Pohcfa43+NMUFnSSVCLdu8m5smLqRDcl2ev/x4YqNtVxtjgs+ONBFoc84Brpowj/rxsUwY28e6sDfGhEyV61RMeNu9v4Axr83lQEER794wgOR6tb0OyRhTg9iVSgTJLyxi3Jvz2bAzl/9e0YsOyXW9DskYU8PYlUqEKC5W7py2hDm//MrTl/VgQNvGXodkjKmB7EolQjzxxWr+t3gLd57RkfN6tPA6HGNMDWVJJQK8OXsjL367jpEnpHLjoLZeh2OMqcEsqVRzX67I4oEPlzG4U1P+79yudi+KMcZTQU0qItJARN4RkVUislJE+otIDxGZLSKLRGS+iPQNZgyRbPGmHG6ZvJBuLerzn5E9ibF7UYwxHgt2Rf3TwOeqOlxE4oAEYCrwkKp+JiJnAU8Ag4IcR8TJ2Lmfq1+fR5O6tXh1dB8S4qzNhTHGe0E7EolIPZzHDo8BUNWDwEERUaCeO1l9rLfjKtuVe5Ax4+dSWKxMGNuXJnVreR2SMcYAwb1SaYPzIK/xInIcsADnYV+3AV+IyJM4xW8DyppZRMbhPL6Y1NTUIIZZveQVFHHNG/PJzDnApGtOoG2TOl6HZIwxvwlmIXwMcDzwgqr2BHKBe4AbgNtVtSVwO/BqWTOr6kuq2ltVezdpYs//ACgqVm6fsoiFGbt46tIe9E5r5HVIxhhzmGAmlUwgU1XnuO/fwUkyo4H33GHTAKuo99Mjn6zks2Xb+OtZnTnr2GZeh2OMMb8TtKSiqtuATSJS8tjhwcAKnDqUU9xhpwFrghVDJHn1h1947cdfGDMgjasHtvY6HGOMKVOwmwzdAkx0W36tB8YCHwJPi0gMkIdbb2LK99nSrTz8yQrO6JrMfed0sXtRjDFhK6hJRVUXAb1LDf4B6BXM9UaS+Rt+5dYpi+jZsgFPX9aT6ChLKMaY8GV3y4Wx9dn7uOaN+bRoEM8ro/tQOzba65CMMaZCllTC1I59+YwZP49oESaM7UOjxDivQzLGmErZbdhhaP/BQq6eMI/te/N4e1x/WiUleh2SMcb4xa5UwkxhUTF/nJzO0s27+c+I4+nRsoHXIRljjN/sSiWMqCoPfrScr1Zu5//O68qQLsleh2SMMVViVyph5MVv1/PW7AyuO7kNV/ZP8zocY4ypMksqYeLDRZv5x+er+MNxzbn7zE5eh2OMMUfEkkoYmLVuJ3dMW0zf1o148uLuRNm9KMaYasqSisd+ztrLuDfn0yopkZev6E2tGLsXxRhTfVlS8VDWnjzGjp9H7dhoJoztQ/2EWK9DMsaYo2JJxSP78gsZO34eu/YfZPyYPqQ0TPA6JGOMOWrWpNgDBUXF3DhxIauz9vLK6N50a1Hf65CMMSYg7EolxFSVv76/lO9+zuaR87txasemXodkjDEBY0klxJ75ei1T52dyy2ntuKyvPSbZGBNZLKmE0LT5m/j3Vz9z4fEt+NOQDl6HY4wxAWdJJUS++zmbe99bysB2jXn8wu72oC1jTESypBICK7bs4caJC2nXtA7PjzqeuBjb7MaYyBTUo5uINBCRd0RklYisFJH+7vBbRGS1iCwXkSeCGYPXtuQcYOyEudSpFcP4sX2oV9vuRTHGRK5gNyl+GvhcVYe7z6lPEJFTgfOA7qqaLyIR2/xp94ECxo6fx/78Iqbd0J9m9eO9DskYY4IqaElFROoBJwNjAFT1IHBQRG4AHlfVfHf49mDF4KWDhcVc/+YC1mXv4/Wr+tLpmHpeh2SMMUEXzOKvNkA2MF5E0kXkFRFJBDoAJ4nIHBH5VkT6lDWziIwTkfkiMj87OzuIYQaeqnL3u0uYtX4n/7ioOye2a+x1SMYYExLBTCoxwPHAC6raE8gF7nGHNwT6AXcCU6WMplCq+pKq9lbV3k2aNAlimIH35PTVvJ++mT8P6cBFvVK8DscYY0ImmEklE8hU1Tnu+3dwkkwm8J465gLFQMScyk+ak8FzM9ZxWZ+W3HxaO6/DMcaYkApaUlHVbcAmEenoDhoMrAA+AE4DEJEOQBywI1hxhNI3q7L42wdLGdSxCQ+f383uRTHG1DjBbv11CzDRbfm1HhiLUwz2mogsAw4Co1VVgxxH0C3JzOGmiel0aV6P50YeT0y03YtijKl5gppUVHUR0LuMUaOCud5Q2/Trfq6aMI9GiXG8NqYPibWs82djTM1kR7+jlLP/IKPHz6WgSHl7XB+a1q3tdUjGGOMZK6M5CnkFRVz7xnwyfz3AS1f0ol3Tul6HZIwxnrIrlSNUXKz8edpi5m3YxTMjenJCmySvQzLGGM/ZlcoReuyzlXyyZCv3DuvEucc19zocY4wJC5ZUjsCEH3/h5e9/4cr+rRh3chuvwzHGmLBhSaWKPl+2jYc+XsGQLsk88Ieudi+KMcb4sKRSBQs27uLWt9M5LqUBz1zWk+goSyjGGOPLkoqfftmRyzWvz+OY+rV5dXRv4uOivQ7JGGPCjiUVP+zcl8+Y8XMBmDC2L0l1ankckTHGhCdrUlyJAweLuPr1+Wzbnceka/vRunGi1yEZY0zYsqRSgaJi5Y9vp7M4M4cXLu9Fr1YNvQ7JGGPCmhV/lUNV+b+PlvPliizuP6cLZ3Y7xuuQjDEm7FlSKcfL36/n9VkbuWZga8ae2NrrcIwxplqwpFKGjxZv4dFPV3H2sc34y1mdvQ7HGGOqDUsqpcxZv5M/T11Mn7SG/L9LjiPK7kUxxhi/WVLxsXb7Xq59Yz4pjeJ5+cre1I61e1GMMaYqLKm4tu/NY/Rr84iLieL1sX1pkBDndUjGGFPtBDWpiEgDEXlHRFaJyEoR6e8z7g4RURFpHMwY/JGbX8hVE+bxa+5BXhvTh5aNErwOyRhjqqVg36fyNPC5qg53n1OfACAiLYEhQEaQ11+pwqJibp60kBVb9vDylb3pntLA65CMMabaCtqViojUA04GXgVQ1YOqmuOO/jdwF6DBWr8/VJX7PlzGjNXZ/P38bgzunOxlOMYYU+0Fs/irDZANjBeRdBF5RUQSReRcYLOqLq5oZhEZJyLzRWR+dnZ2UAJ8bsZaJs/dxI2D2nL5Ca2Csg5jjKlJgplUYoDjgRdUtSeQCzwI/BW4v7KZVfUlVe2tqr2bNGkS8ODeW5jJk9N/5vwezbnzjI4BX74xxtREwUwqmUCmqs5x37+Dk2RaA4tFZAOQAiwUkZD2gfLj2h3c9c4S+rdJ4onhx9mDtowxJkCCllRUdRuwSURKLgMGAwtVtamqpqlqGk7iOd6dNiRWbdvD9W8uoE2TRF68ohdxMdaq2hhjAiXYrb9uASa6Lb/WA2ODvL4Kbd19gDGvzSOhVjQTxvalfnysl+EYY0zECWpSUdVFQO8KxqcFc/2+9uQVMHb8PPbmFTD1+v40bxAfqlUbY0yNUSOep3KwsJgb31rI2u37eG1MH7o2r+91SMYYE5EiPqmoKve8t4Qf1u7gn8O7c3KHwLckM8YY44j4Wup/f/kz7y3czG2nt+fi3i29DscYYyJaRCeVt+dm8Mw3a7mkdwq3Dm7vdTjGGBPxIjqpHCwqZlDHJjxywbF2L4oxxoRARNepXNk/jVEntLIHbRljTIhE9JUKYAnFGGNCKOKTijHGmNCxpGKMMSZgLKkYY4wJGEsqxhhjAsaSijHGmICxpGKMMSZgLKkYY4wJGFFVr2OolIhkAxuPcPbGwI4AhhMoFlfVWFxVY3FVTbjGBUcXWytVDWkvutUiqRwNEZmvquU+08UrFlfVWFxVY3FVTbjGBeEdW1ms+MsYY0zAWFIxxhgTMDUhqbzkdQDlsLiqxuKqGourasI1Lgjv2H4n4utUjDHGhE5NuFIxxhgTIpZUjDHGBExEJBUReU1EtovIsnLGi4g8IyJrRWSJiBwfJnENEpHdIrLI/bs/RHG1FJEZIrJSRJaLyK1lTBPybeZnXCHfZiJSW0TmishiN66HypimlohMcbfXHBFJC5O4xohIts/2uibYcfmsO1pE0kXk4zLGhXx7+RmXJ9tLRDaIyFJ3nfPLGO/JMeyIqGq1/wNOBo4HlpUz/izgM0CAfsCcMIlrEPCxB9urGXC8+7ou8DPQxett5mdcId9m7jao476OBeYA/UpNcyPwovv6MmBKmMQ1Bng21N8xd91/AiaVtb+82F5+xuXJ9gI2AI0rGO/JMexI/iLiSkVVvwN+rWCS84A31DEbaCAizcIgLk+o6lZVXei+3gusBFqUmizk28zPuELO3Qb73Lex7l/pFi7nAa+7r98BBotIUB876mdcnhCRFOBs4JVyJgn59vIzrnDlyTHsSEREUvFDC2CTz/tMwuBg5ervFl98JiJdQ71yt9ihJ85Zri9Pt1kFcYEH28wtMlkEbAe+VNVyt5eqFgK7gaQwiAvgIrfI5B0RaRnsmFxPAXcBxeWM92R7+REXeLO9FJguIgtEZFwZ48P5GHaYmpJUyjoDCoczuoU4ffMcB/wH+CCUKxeROsC7wG2quqf06DJmCck2qyQuT7aZqhapag8gBegrIt1KTeLJ9vIjro+ANFXtDnzFoauDoBGRc4DtqrqgosnKGBbU7eVnXCHfXq4TVfV4YBhwk4icXGp8uB7DfqemJJVMwPeMIwXY4lEsv1HVPSXFF6r6KRArIo1DsW4RicU5cE9U1ffKmMSTbVZZXF5uM3edOcBM4MxSo37bXiISA9QnhEWf5cWlqjtVNd99+zLQKwThnAicKyIbgLeB00TkrVLTeLG9Ko3Lo+2Fqm5x/28H3gf6lpokLI9hZakpSeV/wJVuC4p+wG5V3ep1UCJyTEk5soj0xdkfO0OwXgFeBVaq6r/KmSzk28yfuLzYZiLSREQauK/jgdOBVaUm+x8w2n09HPhG3RpWL+MqVe5+Lk49VVCp6r2qmqKqaTiV8N+o6qhSk4V8e/kTlxfbS0QSRaRuyWtgKFC6xWhYHsPKEuN1AIEgIpNxWgU1FpFM4AGcSktU9UXgU5zWE2uB/cDYMIlrOHCDiBQCB4DLgv3Dcp0IXAEsdcvjAf4CpPrE5sU28ycuL7ZZM+B1EYnGSWJTVfVjEfk/YL6q/g8nGb4pImtxzrgvC3JM/sb1RxE5Fyh04xoTgrjKFAbby5+4vNheycD77rlSDDBJVT8XkevB22PYkbBuWowxxgRMTSn+MsYYEwKWVIwxxgSMJRVjjDEBY0nFGGNMwFhSMcYYEzCWVIwxxgSMJRVjwpTbHXrIegswJhAsqRhjjAkYSyomoohImjgP+XpZnAdXTReReBGZKSK93Wkau/0/lTyU6QMR+UhEfhGRm0XkT+I8xGm2iDSqYF1tReRzt2fZ70Wkkzt8goi86A772e3IsOShWuPFeRhTuoic6g6PFpEn3eFLROQWn9XcIiIL3XGdgrXdjAkUSyomErUHnlPVrkAOcFEl03cDRuJ04vcIsF9VewKzgCsrmO8l4BZV7QXcATzvMy4NOAXn2R0vikht4CYAVT0WGIHTxUptYBzQGujp9o470Wc5O9zea19w12FMWIuIvr+MKeUXVS3pO2wBzgG+IjPch4LtFZHdON2fAywFupc1g9s9/wBgmhx6tlQtn0mmqmoxsEZE1gOdgIE43fWjqqtEZCPQAacjyBfd54qgqr699Zb01LwAuLCSz2GM5yypmEiU7/O6CIjH6SCw5Mq8dgXTF/u8L6b830gUkOM+y6QspTvVU8p+Jgbu8PI64SuJpaiCWIwJG1b8Jz/OEQAAANVJREFUZWqKDRx6Nsbwo12Y+/CwX0TkYnC67ReR43wmuVhEokSkLdAGWA18B1zuTt8Bp/fl1cB04Hr3uSJUVI9jTLizpGJqiidxusz/CQhUM93LgatFZDGwHOc54iVWA98CnwHXq2oeTp1LtIgsBaYAY9wHQr0CZABL3GWNDFB8xoScdX1vTICJyATgY1V9x+tYjAk1u1IxxhgTMHalYkwlROQ5nKdS+npaVcd7EY8x4cySijHGmICx4i9jjDEBY0nFGGNMwFhSMcYYEzCWVIwxxgTM/wd/9W4PabCSFQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Ting-Liang Huang\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "\n",
    "try:\n",
    "   import _pickle as pickle\n",
    "except:\n",
    "   import pickle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# This is a class for a LinearTransform layer which takes an input \n",
    "# weight matrix W and computes W x as the forward step\n",
    "class LinearTransform(object):\n",
    "\n",
    "    def __init__(self, W, b):\n",
    "        # DEFINE __init function:  W, b, momentum_parameter\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.w_mom = 0\n",
    "        self.b_mom = 0\n",
    "    def forward(self, x):\n",
    "        # DEFINE forward function\n",
    "        # Calculate z = W.T*x + b\n",
    "        self.x = x\n",
    "        z = np.dot(self.x, self.W) + self.b\n",
    "        return z\n",
    "    \n",
    "    def backward(\n",
    "        self, \n",
    "        grad_output, \n",
    "        learning_rate, \n",
    "        mom, \n",
    "        l2_penalty=0,\n",
    "    ):\n",
    "        # DEFINE backward function\n",
    "        # Update w and b\n",
    "        dx = np.dot(grad_output, self.W.T)\n",
    "        self.w_mom = mom * self.w_mom - learning_rate * np.dot(self.x.T, grad_output)\n",
    "        self.b_mom = mom * self.b_mom - learning_rate * np.sum(grad_output, axis=0)\n",
    "        self.W += self.w_mom\n",
    "        self.b += self.b_mom\n",
    "        return dx, self.W, self.b\n",
    "\n",
    "# ADD other operations in LinearTransform if needed\n",
    "\n",
    "# This is a class for a ReLU layer max(x,0)\n",
    "class ReLU(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # DEFINE forward function\n",
    "        self.x = x\n",
    "        self.output = (x * (x > 0))\n",
    "        return self.output\n",
    "    \n",
    "    def backward(\n",
    "        self, \n",
    "        grad_output, \n",
    "        learning_rate=None, \n",
    "        momentum=None, \n",
    "        l2_penalty=None,\n",
    "    ):\n",
    "        # DEFINE backward function\n",
    "        # Derivative relu\n",
    "        self.output[self.output > 0] = 1 \n",
    "        out = grad_output * self.output\n",
    "        return out\n",
    "\n",
    "# ADD other operations in ReLU if needed\n",
    "\n",
    "# This is a class for a sigmoid layer followed by a cross entropy layer, the reason \n",
    "# this is put into a single layer is because it has a simple gradient form\n",
    "class SigmoidCrossEntropy(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # DEFINE forward function\n",
    "        self.sigmoid = 1.0 / (1.0 + np.exp(-x))\n",
    "        return self.sigmoid\n",
    "        \n",
    "    def backward(\n",
    "        self, \n",
    "        y,\n",
    "        grad_output,\n",
    "        learning_rate=0.0,\n",
    "        momentum=0.0,\n",
    "        l2_penalty=0.0\n",
    "    ):\n",
    "        # DEFINE backward function\n",
    "        self.y = y\n",
    "        d = grad_output * (self.sigmoid - self.y)\n",
    "        return d\n",
    "        \n",
    "# This is a class for the Multilayer perceptron\n",
    "class MLP(object):\n",
    "\n",
    "    def __init__(self, input_dims, hidden_units):\n",
    "        # INSERT CODE for initializing the network\n",
    "        self.input_dims = input_dims\n",
    "        self.hidden_units = hidden_units        \n",
    "        self.w_1 = np.random.standard_normal((input_dims, hidden_units))\n",
    "        self.b_1 = np.random.standard_normal((1, hidden_units))\n",
    "        self.w_2 = np.random.standard_normal((hidden_units, 1))\n",
    "        self.b_2 = np.random.standard_normal((1, 1))\n",
    "        self.l1 = LinearTransform(self.w_1, self.b_1)\n",
    "        self.l2 = LinearTransform(self.w_2, self.b_2)\n",
    "        self.relu = ReLU()\n",
    "        self.SCE = SigmoidCrossEntropy()\n",
    "        self.y_pred = 0\n",
    "        self.x_ = 0\n",
    "        self.y_ = 0\n",
    "        \n",
    "    def train(\n",
    "        self,\n",
    "        x,\n",
    "        y,\n",
    "        batch_size,\n",
    "        learning_rate,\n",
    "        momentum,\n",
    "        l2_penalty\n",
    "    ):\n",
    "        # INSERT CODE for training the network\n",
    "        self.x_ = x[b * batch_size: (b + 1) * batch_size, :]\n",
    "        self.y_ = y[b * batch_size: (b + 1) * batch_size, :]\n",
    "        # Forward\n",
    "        z_1 = self.l1.forward(self.x_)\n",
    "        z_1_relu = self.relu.forward(z_1)\n",
    "        z_2 = self.l2.forward(z_1_relu)\n",
    "        z_2_SCE = self.SCE.forward(z_2)\n",
    "        self.y_pred = np.round(z_2_SCE)\n",
    "        # Backprop\n",
    "        d_z = self.SCE.backward(self.y_, 1)\n",
    "        dx_2, dw_2, db_2 = self.l2.backward(d_z, learning_rate, momentum)\n",
    "        dx2_r = self.relu.backward(dx_2)\n",
    "        dx_1, dw_1, db_1 = self.l1.backward(dx2_r, learning_rate, momentum)\n",
    "\n",
    "    def Loss_function(self, l2_penalty):\n",
    "        L = -1 * (self.y_ * np.log(self.y_pred + 10e-8) + (1.0 - self.y_) * np.log(1.0 - self.y_pred + 10e-8))\n",
    "        L += l2_penalty / 2 * (np.sum(np.square(self.w_1)) + np.sum(np.square(self.w_2)))\n",
    "        accuracy = 100 * np.mean((np.round(self.y_pred) == self.y_))\n",
    "        avg_loss = np.mean(L)\n",
    "        return accuracy, avg_loss\n",
    "\n",
    "    def evaluate(self, x, y, batch_size, l2_penalty):\n",
    "        # INSERT CODE for testing the network\n",
    "        num_data = x.shape[0]\n",
    "        num_b = round(num_data/batch_size)\n",
    "        \n",
    "        b_loss, b_acc = [], []\n",
    "        # Make data into different batches.\n",
    "        for b in range(num_b):\n",
    "            x_ = x[b * b: (b + 1) * batch_size, :]\n",
    "            y_ = y[b * b: (b + 1) * batch_size, :]\n",
    "\n",
    "            # Forward \n",
    "            z_1 = self.l1.forward(x_)\n",
    "            z_1_relu = self.relu.forward(z_1)\n",
    "            z_2 = self.l2.forward(z_1_relu)\n",
    "            z_2_SCE = self.SCE.forward(z_2)\n",
    "            y_pred = np.round(z_2_SCE)\n",
    "\n",
    "            # Calculate loss and accuracy\n",
    "            L = -1 * (y_ * np.log(y_pred + 10e-8) + (1.0 - y_) * np.log(1.0 - y_pred + 10e-8))\n",
    "            L += l2_penalty / 2 * (np.sum(np.square(self.w_1)) + np.sum(np.square(self.w_2)))\n",
    "            accuracy = 100 * np.mean(y_pred == y_)\n",
    "            avg_loss = np.mean(L)\n",
    "            b_loss.append(avg_loss)\n",
    "            b_acc.append(accuracy)\n",
    "\n",
    "        return np.mean(b_loss), np.mean(b_acc)\n",
    "    # ADD other operations and data entries in MLP if needed\n",
    "# Function for normalization\n",
    "def normalization(x):\n",
    "    x_max = np.max(x, axis = 0)\n",
    "    x_nor = x / x_max\n",
    "    x_mean_train = np.mean(x_nor, axis = 0)\n",
    "    x = (x_nor - x_mean_train)\n",
    "    return x\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    # Read data\n",
    "    if sys.version_info[0] < 3:\n",
    "        data = pickle.load(open('cifar_2class_py2.p', 'rb'))\n",
    "    else:\n",
    "        data = pickle.load(open('cifar_2class_py2.p', 'rb'), encoding='bytes')\n",
    "    \n",
    "    x_train_row = data[b'train_data']\n",
    "    y_train = data[b'train_labels']\n",
    "    x_test_row = data[b'test_data']\n",
    "    y_test = data[b'test_labels']\n",
    "    \n",
    "    num_data, input_dims = x_train_row.shape\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # Data Normalization\n",
    "    x_train = normalization(x_train_row)\n",
    "    x_test = normalization(x_test_row)\n",
    "\n",
    "    # YOU CAN CHANGE num_epochs AND num_batches TO YOUR DESIRED VALUES\n",
    "    # Parameters that can be change to test the efficiency of DNN\n",
    "    \n",
    "    print('-------------------------------best scenario-------------------------------')\n",
    "    hidden_units = 128\n",
    "    learning_rate = 0.005\n",
    "    momentum = 0.8\n",
    "    num_epochs = 5\n",
    "    batch_size = 64\n",
    "    l2_penalty = 0\n",
    "    # Create DNN model\n",
    "    model = MLP(input_dims, hidden_units)\n",
    "    ttl_train_loss, ttl_train_acc, ttl_val_loss, ttl_val_acc = [], [], [], []\n",
    "    for epoch in range(num_epochs):\n",
    "        num_b = num_data // batch_size\n",
    "    # INSERT YOUR CODE FOR EACH EPOCH HERE\n",
    "        train_loss_set, train_acc_set = [], []\n",
    "        for b in range(num_b):\n",
    "            # Feed data to model and get training accuracy\n",
    "            model.train(x_train, y_train, batch_size, learning_rate, momentum, l2_penalty)\n",
    "            train_acc, train_loss = model.Loss_function(l2_penalty)\n",
    "            train_loss_set.append(np.mean(train_loss))\n",
    "            train_acc_set.append(np.mean(train_acc))\n",
    "        ttl_train_loss.append(np.mean(train_loss_set))\n",
    "        ttl_train_acc.append(np.mean(train_acc_set))\n",
    "        # Feed the validation data to trained model and test accuracy\n",
    "        val_loss, val_acc = model.evaluate(x_test, y_test, batch_size, l2_penalty)\n",
    "        ttl_val_acc.append(val_acc)\n",
    "        ttl_val_loss.append(val_loss)\n",
    "        print(\"[Epoch {}/{}] train_loss: {:.3f}  train_accuracy: {:.3f}%  validation_loss: {:.3f}  validation_accuracy: {:.3f}%\".format(epoch+1, num_epochs, np.mean(train_loss_set), np.mean(train_acc_set), np.mean(val_loss), np.mean(val_acc)))\n",
    "    print(\"Best accuracy => train_accuracy: {:.3f}%  validation_accuracy: {:.3f}%\".format(np.max(ttl_train_acc), np.max(ttl_val_acc)))\n",
    "    a_axis = range(1,num_epochs+1)\n",
    "    plt.plot(a_axis, ttl_train_acc)\n",
    "    plt.plot(a_axis, ttl_val_acc)\n",
    "    plt.xlabel('num_epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('lr=0.0005, hidden_units=128, momentum=0.8, batch_size=64')\n",
    "    plt.legend(['training', 'testing'])\n",
    "    plt.savefig('best_scenario_plot.jpg')    \n",
    "    '''\n",
    "    print('---------------test accuracy with different number of batch size---------------')\n",
    "    hidden_units = 256\n",
    "    learning_rate = 0.0005\n",
    "    momentum = 0.8\n",
    "    num_epochs = 30\n",
    "    batch_size = [64, 128, 256, 512]\n",
    "    l2_penalty = 0\n",
    "    # Create DNN model\n",
    "    diff_batch_acc = []\n",
    "    for size in batch_size:\n",
    "        print('batch size = {}'.format(size))\n",
    "        model = MLP(input_dims, hidden_units)\n",
    "        ttl_train_loss, ttl_train_acc, ttl_val_loss, ttl_val_acc = [], [], [], []\n",
    "        for epoch in range(num_epochs):\n",
    "            num_b = num_data // size\n",
    "        # INSERT YOUR CODE FOR EACH EPOCH HERE\n",
    "            train_loss_set, train_acc_set = [], []\n",
    "            for b in range(num_b):\n",
    "                # Feed data to model and get training accuracy\n",
    "                model.train(x_train, y_train, size, learning_rate, momentum, l2_penalty)\n",
    "                train_acc, train_loss = model.Loss_function(l2_penalty)\n",
    "                train_loss_set.append(np.mean(train_loss))\n",
    "                train_acc_set.append(np.mean(train_acc))\n",
    "            ttl_train_loss.append(np.mean(train_loss_set))\n",
    "            ttl_train_acc.append(np.mean(train_acc_set))\n",
    "            # Feed the validation data to trained model and test accuracy\n",
    "            val_loss, val_acc = model.evaluate(x_test, y_test, size, l2_penalty)\n",
    "            ttl_val_acc.append(val_acc)\n",
    "            ttl_val_loss.append(val_loss)\n",
    "            print(\"[Epoch {}/{}] train_loss: {:.3f}  train_accuracy: {:.3f}%  validation_loss: {:.3f}  validation_accuracy: {:.3f}%\".format(epoch+1, num_epochs, np.mean(ttl_train_loss), np.mean(ttl_train_acc), np.mean(ttl_val_loss), np.mean(ttl_val_acc)))\n",
    "        print(\"Best accuracy => train_accuracy: {:.3f}%  validation_accuracy: {:.3f}%\".format(np.max(ttl_train_acc), np.max(ttl_val_acc)))\n",
    "        diff_batch_acc.append(ttl_val_acc)\n",
    "    a_axis = range(1,num_epochs+1)\n",
    "    plt.plot(a_axis, diff_batch_acc[0])\n",
    "    plt.plot(a_axis, diff_batch_acc[1])\n",
    "    plt.plot(a_axis, diff_batch_acc[2])\n",
    "    plt.plot(a_axis, diff_batch_acc[3])\n",
    "    plt.xlabel('num_epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend(['b_size=64','b_size=128', 'b_size=256','b_size=512'])\n",
    "    plt.title('test accuracy with different number of batch size')\n",
    "    plt.savefig('diff_num_b_size.jpg')        \n",
    "    \n",
    "    print('---------------test accuracy with different learning rate---------------')\n",
    "    hidden_units = 256\n",
    "    learning_rate = [0.05, 0.005, 0.0005, 0.00005]\n",
    "    momentum = 0.8\n",
    "    num_epochs = 10\n",
    "    batch_size = 128\n",
    "    l2_penalty = 0\n",
    "    # Create DNN model\n",
    "    diff_lr_acc = []\n",
    "    for lr in learning_rate:\n",
    "        print('learning rate = {}'.format(lr))\n",
    "        model = MLP(input_dims, hidden_units)\n",
    "        ttl_train_loss, ttl_train_acc, ttl_val_loss, ttl_val_acc = [], [], [], []\n",
    "        for epoch in range(num_epochs):\n",
    "            num_b = num_data // batch_size\n",
    "        # INSERT YOUR CODE FOR EACH EPOCH HERE\n",
    "            train_loss_set, train_acc_set = [], []\n",
    "            for b in range(num_b):\n",
    "                # Feed data to model and get training accuracy\n",
    "                model.train(x_train, y_train, batch_size, lr, momentum, l2_penalty)\n",
    "                train_acc, train_loss = model.Loss_function(l2_penalty)\n",
    "                train_loss_set.append(np.mean(train_loss))\n",
    "                train_acc_set.append(np.mean(train_acc))\n",
    "            ttl_train_loss.append(np.mean(train_loss_set))\n",
    "            ttl_train_acc.append(np.mean(train_acc_set))\n",
    "            # Feed the validation data to trained model and test accuracy\n",
    "            val_loss, val_acc = model.evaluate(x_test, y_test, batch_size, l2_penalty)\n",
    "            ttl_val_acc.append(val_acc)\n",
    "            ttl_val_loss.append(val_loss)\n",
    "            print(\"[Epoch {}/{}] train_loss: {:.3f}  train_accuracy: {:.3f}%  validation_loss: {:.3f}  validation_accuracy: {:.3f}%\".format(epoch+1, num_epochs, np.mean(ttl_train_loss), np.mean(ttl_train_acc), np.mean(ttl_val_loss), np.mean(ttl_val_acc)))\n",
    "        print(\"Best accuracy => train_accuracy: {:.3f}%  validation_accuracy: {:.3f}%\".format(np.max(ttl_train_acc), np.max(ttl_val_acc)))\n",
    "        diff_lr_acc.append(ttl_val_acc)\n",
    "    a_axis = range(1,num_epochs+1)\n",
    "    plt.plot(a_axis, diff_lr_acc[0])\n",
    "    plt.plot(a_axis, diff_lr_acc[1])\n",
    "    plt.plot(a_axis, diff_lr_acc[2])\n",
    "    plt.plot(a_axis, diff_lr_acc[3])\n",
    "    plt.xlabel('num_epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend(['0.0005', '0.00005', '0.000005', '0.0000005'])\n",
    "    plt.title('test accuracy with different learning rate')\n",
    "    plt.savefig('diff_lr.jpg')         \n",
    "    \n",
    "    print('---------------test accuracy with different number of hidden units---------------')    \n",
    "    hidden_units = [64,128,256,512,1024]\n",
    "    learning_rate = 0.0005\n",
    "    momentum = 0.8\n",
    "    num_epochs = 10\n",
    "    batch_size = 64\n",
    "    l2_penalty = 0\n",
    "    # Create DNN model\n",
    "    diff_h_u = []\n",
    "    for u in hidden_units:\n",
    "        print('hidden_units = {}'.format(u))\n",
    "        model = MLP(input_dims, u)\n",
    "        ttl_train_loss, ttl_train_acc, ttl_val_loss, ttl_val_acc = [], [], [], []\n",
    "        for epoch in range(num_epochs):\n",
    "            num_b = num_data // batch_size\n",
    "        # INSERT YOUR CODE FOR EACH EPOCH HERE\n",
    "            train_loss_set, train_acc_set = [], []\n",
    "            for b in range(num_b):\n",
    "                # Feed data to model and get training accuracy\n",
    "                model.train(x_train, y_train, batch_size, learning_rate, momentum, l2_penalty)\n",
    "                train_acc, train_loss = model.Loss_function(l2_penalty)\n",
    "                train_loss_set.append(np.mean(train_loss))\n",
    "                train_acc_set.append(np.mean(train_acc))\n",
    "            ttl_train_loss.append(np.mean(train_loss_set))\n",
    "            ttl_train_acc.append(np.mean(train_acc_set))\n",
    "            # Feed the validation data to trained model and test accuracy\n",
    "            val_loss, val_acc = model.evaluate(x_test, y_test, batch_size, l2_penalty)\n",
    "            ttl_val_acc.append(val_acc)\n",
    "            ttl_val_loss.append(val_loss)\n",
    "            print(\"[Epoch {}/{}] train_loss: {:.3f}  train_accuracy: {:.3f}%  validation_loss: {:.3f}  validation_accuracy: {:.3f}%\".format(epoch+1, num_epochs, np.mean(train_loss_set), np.mean(train_acc_set), np.mean(val_loss), np.mean(val_acc)))\n",
    "        print(\"Best accuracy => train_accuracy: {:.3f}%  validation_accuracy: {:.3f}%\".format(np.max(ttl_train_acc), np.max(ttl_val_acc)))\n",
    "        diff_h_u.append(ttl_val_acc)\n",
    "    a_axis = range(1,num_epochs+1)\n",
    "    plt.plot(a_axis, diff_h_u[0])\n",
    "    plt.plot(a_axis, diff_h_u[1])\n",
    "    plt.plot(a_axis, diff_h_u[2])\n",
    "    plt.plot(a_axis, diff_h_u[3])\n",
    "    plt.plot(a_axis, diff_h_u[4])\n",
    "    plt.xlabel('num_epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('test accuracy with different number of hidden units')\n",
    "    plt.legend(['64','128','256','512','1024'])\n",
    "    plt.savefig('diff_hidden_units.jpg')        \n",
    "    '''\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
